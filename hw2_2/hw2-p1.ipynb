{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ff2b380279942fdf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# **Homework 2 Problem 1 (22 points) [TA: Anurata Hridi]**\n",
    "\n",
    "In this problem, you'll be exploring decision trees. \n",
    "\n",
    "## Instructions:\n",
    "1. Use github.ncsu.edu to submit your work repository if you have not done so yet. It is your responsbility to ensure the TAs have access to your work before the deadline. Make sure the repo is private.\n",
    "2. Do not modify the code structure given. Answer the questions in the designated space.\n",
    "\n",
    "All the best!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9ccf1b7d453b3ab2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.0) Loading Data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-666dda52be60099f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m執行具有 'Python 3.13.0' 的儲存格需要 ipykernel 套件。\n",
      "\u001b[1;31m執行下列命令以將 'ipykernel' 安裝到 Python 環境中。\n",
      "\u001b[1;31m命令: '/bin/python3.13 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Remember you have to run this cell block before continuing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-437124e0e6f1c1a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Important Note about Non-Determinism (Randomness)\n",
    "Here on forward, we're going to be using a lot of methods that have some randomness in their output. To address this, most sklearn libraries/functions allow you to a `random_state` parameter, which allows the methods to have consistent output each time you run them. Make sure to set `random_state=random_seed` so we can reproduce and check your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bd608959b76348c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# set a seed for reproducibility\n",
    "random_seed = 25\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f5ce495af5618551",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.1) Building Trees & Interpretation (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-20a6ba47167c6cc6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Your goal is to create a set of *human-interpretable* rules to tell seeds apart**. \n",
    "\n",
    "You will make a decision tree using the heart diseases dataset, evaluate its performance, and interpret its rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-544ce0b4d187f3e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# Read the seeds dataset and translate to pandas dataframe\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Define column names for the dataset\n",
    "column_names = ['Area', 'Perimeter', 'Compactness', 'KernelLength', 'KernelWidth', 'AsymmetryCoefficient', 'KernelGrooveLength', 'Class']\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt'\n",
    "seeds_df = pd.read_csv(url, delim_whitespace=True, header=None, names=column_names)\n",
    "\n",
    "# Make sure data is in the same range\n",
    "seeds_temp_df = MinMaxScaler().fit_transform(seeds_df.iloc[:, :-1])\n",
    "\n",
    "seeds_temp_df = pd.DataFrame(seeds_temp_df, columns = ['Area', 'Perimeter', 'Compactness', 'KernelLength', 'KernelWidth', 'AsymmetryCoefficient', 'KernelGrooveLength'])\n",
    "# Note that the \"class\" attribute is type of wheat\n",
    "seeds_df = pd.concat([seeds_temp_df, seeds_df[\"Class\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-925d5e1670c3ae45",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Building the Tree\n",
    "The fraction of test data should be 20%.\n",
    "\n",
    "As always, use `random_state=random_seed` for all of your model seeds to make sure your ouput is reproducable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2faed7640ff1a213",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(random_seed)\n",
    "test_data_fraction = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "train_test_split",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Goal: Split the dataset into features and class labels\n",
    "# and split the X and Y datasets into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: Make sure to define these variables in your solution below\n",
    "X_train = X_test = Y_train = Y_test = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "train_test_split-public",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(np.shape(X_train) == (168, 7))\n",
    "assert(len(X_test) == 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "train_test_split-private",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note: We will check your code here against hidden test cases, too.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bff671d8373be2a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now use the diagram generated to interpret the tree. If you had to write some human-interpretable rules for classifying seeds, what would they be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1834daec7e1013ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 2) Pruning & Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6eb7fd4dd6bba511",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.1 Example: Pre-Pruning (4 pts)\n",
    "\n",
    "Below we will give some examples of how to use pre-pruning hyperparameters. You will answer some written questions throught this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-726775266493d8f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Below we have written some example code to train a decision tree, plot it, and calculate its accuracy.\n",
    "\n",
    "**Note**: We use the parameter `max_depth=2` to constrain the size and complexity of your decision tree. Remember this is a form of *pre-pruning*.\n",
    "\n",
    "**Hint**: You may need to right-click and download the figure in order to view it. One some versions, you may need to shift-right-click.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Goal: Train a decision tree, plot it, and calculate its accuracy.\n",
    "from sklearn.metrics import accuracy_score\n",
    "gini_tree = DecisionTreeClassifier(criterion = \"gini\", max_depth=2, random_state=random_seed).fit(X=X_train, y=Y_train)\n",
    "plt.figure(figsize=(40,15))\n",
    "seeds_features = seeds_df.iloc[:,0:-1]\n",
    "_ = plot_tree(gini_tree, feature_names=seeds_features.columns)\n",
    "print(f'Train Accuracy: {accuracy_score(Y_train, gini_tree.predict(X_train))}')\n",
    "print(f'Test Accuracy: {accuracy_score(Y_test, gini_tree.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9db41f692cd1ed51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the above example, we set the `max_depth=2`. Play around with different values for `max_depth`. How does the training/test accuracy change? What is the biggest the tree can be (without pre-pruning)? What do you think is the right size of the tree? Why? **Discuss and explain your reasoning here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3c7e4a63c0ca8534",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Min Impurity Decrease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-44c1e78309733a67",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Read the documentation for [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) and take note of the various params that can be used for pre-pruning. We will go in detail on `min_impurity_decrease` together.\n",
    "\n",
    "This parameter set the minimium amount that the impurity (e.g. GINI Index) must go down when we split on a node, for that split to be allowed. If the minimum is 0 (default), this isn't a restriction. If it is high (e.g. 0.3), only very effective splits will be allowed, and we'll have a smaller tree. Note that this is still *pre-pruning* because we stop the tree from growing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impurity_decrease = 0.05\n",
    "gini_tree = DecisionTreeClassifier(criterion = \"gini\", random_state=random_seed, min_impurity_decrease=impurity_decrease).fit(X=X_train, y=Y_train)\n",
    "plt.figure(figsize=(20,10))\n",
    "_ = plot_tree(gini_tree, feature_names=seeds_features.columns)\n",
    "print(f\"Accuracy with Impurity Decrease {impurity_decrease}\")\n",
    "print(f'Train Accuracy: {accuracy_score(Y_train, gini_tree.predict(X_train))}')\n",
    "print(f'Test Accuracy: {accuracy_score(Y_test, gini_tree.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, if you go too far you end up decreasing training accuracy\n",
    "impurity_decrease = 0.1\n",
    "gini_tree = DecisionTreeClassifier(criterion = \"gini\", random_state=random_seed, min_impurity_decrease=impurity_decrease).fit(X=X_train, y=Y_train)\n",
    "plt.figure(figsize=(20,10))\n",
    "_ = plot_tree(gini_tree, feature_names=seeds_features.columns)\n",
    "print(f\"Accuracy with Impurity Decrease {impurity_decrease}\")\n",
    "print(f'Train Accuracy: {accuracy_score(Y_train, gini_tree.predict(X_train))}')\n",
    "print(f'Test Accuracy: {accuracy_score(Y_test, gini_tree.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-78f80cd710d59df4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "There are other methods for pre-pruning, but we won't explore them today.\n",
    "Read the documentation for [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) and take note of the various params that can be used for pre-pruning. These are\n",
    "\n",
    "* `max_depth`\n",
    "* `min_samples_split`\n",
    "* `min_samples_leaf`\n",
    "* `max_features`\n",
    "* `max_leaf_nodes`\n",
    "* `min_impurity_decrease` (already covered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-abdafd116c3502ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.2 Post Pruning [Cost Complexity Pruning] (3 pts)\n",
    "\n",
    "Sklearn implements a more advanced form of post-pruning that we haven't covered in class called [cost complexity pruning (CCP)](https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html). The idea is essentially a more complex/robust form of what we've talked about in the seminars - seeing if estimated error improves after pruning certain nodes after the tree is built. The amount of the tree pruned is controlled by the paramater `ccp_alpha`. \n",
    "\n",
    "Below, complete the `dt_performace` function to train and evaluate a decision tree with the given `ccp_alpha` value. Then try some different values of `ccp_alpha` in the range (0,0.3) to see their effect on the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "dt_performance",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def dt_performance(ccp_alpha, X_train, Y_train, X_test, Y_test, random_seed):\n",
    "    gini_tree = train_acc_value = test_acc_value = None\n",
    "    # Build a decision tree using ccp_alpha\n",
    "    ### BEGIN SOLUTION\n",
    "\n",
    "    ### END SOLUTION\n",
    "    return gini_tree, train_acc_value, test_acc_value\n",
    "\n",
    "\n",
    "ccp_alpha = 0.1\n",
    "gini_tree, trainin_acc_value, test_acc_value = dt_performance(ccp_alpha, X_train, Y_train, X_test, Y_test, random_seed)\n",
    "\n",
    "# Now test with multiple ccp_alpha values and see how training and testing accuracy change.\n",
    "print(f\"Accuracy with ccp_alpha={ccp_alpha}\")\n",
    "print(f'Train Accuracy: {accuracy_score(Y_train, gini_tree.predict(X_train))}')\n",
    "print(f'Test Accuracy: {accuracy_score(Y_test, gini_tree.predict(X_test))}')\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "_ = plot_tree(gini_tree, feature_names=seeds_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "dt_performance-public",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(gini_tree.predict(seeds_df.iloc[:3,0:-1]), [1., 1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "dt_performance-private",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Remember there are hidden tests to cross check your implementation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3b943505b98b2f95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 3 Cross Validation and Hyperparmeter Tuning\n",
    "\n",
    "In this problem you will be using cross-validation to evaluate a model and to tune a hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1685625d3f123166",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.1 Example: Basic Cross Validation\n",
    "\n",
    "Here is an example of using K-fold cross validation for hyperpareter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7ff45c4317420233",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next need to define out training dataset and test dataset. Remember we can only use our **training** dataset (`X_train`) to select out hyperparameters, so we'll define that first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize a k-fold splitter\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "# Kf.split() allows you to iterate though the different folds\n",
    "# \"train_index\" are the indices of the training data in that fold\n",
    "# \"test_index\" are the indices of the testing data in that fold\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    print(\"Train: \", train_index)\n",
    "    print(\"Test: \", test_index)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code defined 3 folds of data within the training data. We can use those train/validation combinations to  evaluate a given hyperparameter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c771ea7b8cd219ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.2 Hyperparameter Tuning with CV (3 pts)\n",
    "\n",
    "In practice, you generally won't include your test dataset in hyperparameter tuning as you don't want the selection of hyperparameters being associated with the test data. Therefore, in this exercise we'll be trying out different HPs by constructing validation sets from our training data. For conveninece, let's assume test dataset as the validation dataset for the seeds dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "k_fold",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def k_fold_accuracy(k, model, X_data, Y_data):\n",
    "    \"\"\"\n",
    "    You will need to implement a k-fold cross validation with accuracy as the performance metric.\n",
    "    \n",
    "    Your inputs and outputs are specified as below:\n",
    "    \n",
    "    Input:\n",
    "        k: An integer indicates the number of fold to do cross validation.\n",
    "        model: A DecisionTreeClassifier instance.\n",
    "        X_data: A numpy array of shape (n_data_rows, n_attributes) where n_data_rows refers to \n",
    "              the number of rows in your dataset and n_attributes refers to the number of attributes. \n",
    "              This typically is from the training dataset.\n",
    "        Y_data: A numpy array of shape (n_data_rows, ) containing the class labels for each row in your \n",
    "              dataset. This typically is from the training dataset.\n",
    "    Output:\n",
    "        scores: A list of length k, with scores[i] containing the validation accuracy score for the i-th fold.\n",
    "    \"\"\"\n",
    "    # Init k-fold splitter\n",
    "    kf = KFold(n_splits=k)\n",
    "    scores = []\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "\n",
    "    ### END SOLUTION\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing K-fold\n",
    "k = 3\n",
    "model = DecisionTreeClassifier(criterion = \"gini\", random_state=random_seed)\n",
    "per_fold_acc = k_fold_accuracy(k, model, X_train, Y_train)\n",
    "print(per_fold_acc)\n",
    "np.mean(per_fold_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "k_fold_test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Public tests\n",
    "k = 3\n",
    "test_model = DecisionTreeClassifier(criterion = \"gini\", random_state=234)\n",
    "per_fold_acc = k_fold_accuracy(k, test_model, X_train, Y_train)\n",
    "np.testing.assert_almost_equal(per_fold_acc, [0.9464684210526315, 0.9285473684210527, 0.9106973509933775], decimal = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "k_fold_test_2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Remember there are hiddent tests. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-25cdd55d92fccfb0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "There also exists a built in sklearn function for this, however it is import to know how to perform your own k-fold cross validation split if you want to implement a custom evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "# We're using the trianing dataset here, but remember that CV will\n",
    "# split that data into training and validation sets for each fold\n",
    "# so we get an \"unbiased\" estimate of our test performance.\n",
    "per_fold_acc = cross_val_score(model, X_train, Y_train, cv=KFold(n_splits=k), scoring='accuracy')\n",
    "print(per_fold_acc)\n",
    "np.mean(per_fold_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-83698689c7246562",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "*Why would we ever do this by hand, if there's already a built-in method?* \n",
    "\n",
    "Sometimes our model training process is more complex than just fitting the model. For example, we may want to do:\n",
    "* Feature selection\n",
    "* Normalization / scaling\n",
    "* More complex models not in the sklearn library\n",
    "\n",
    "In these cases, we can still *only use our training data*! You can't use test data to select features - that would be \"cheating.\" So everying that you use your training data for has to occur within the loop we wrote for CV, above, based on the training data for the particular fold we're evaluating.\n",
    "\n",
    "sklearn also has a feature called [Pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html), which we'll be exploring in the future, to make this easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-243eb524b952d5b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.3 Tuning (10 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cc9d2e0b200c57c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this problem you are going to select the best hypterparameter, using *only the training dataset*. No peaking at the test dataset. To estimate how well a given hyperparameter value will do on *unseen* data, we can use Crossvalidation (within the training dataset) to evaluate our model.\n",
    "\n",
    "Let's use this approach to select the best `ccp_alpha` hyperparameter for a Decision Tree model.\n",
    "\n",
    "In the following cell, you should write code to:\n",
    "1. Iterate over all ccp_alpha values. For each ccp_alpha value, do step 2-3.\n",
    "2. Calculate the k_fold validation accuracy using the above funciton.\n",
    "3. Calculate the training accuracy and the validation accuracy.\n",
    "4. Plot both accuracies vs. the ccp_alpha value.\n",
    "\n",
    "Don't forget to set your decision tree's **random_state=random_seed** for consistent output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "hyperparameter_search",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# np.arange generates a list that starts at minimum, ends at maximum, and increments by step\n",
    "alpha_values = np.arange(0, 0.035, 0.002)\n",
    "\n",
    "# two lists to hold our accuracy\n",
    "k = 5\n",
    "valid_accs = []\n",
    "train_accs = []\n",
    "\n",
    "# TODO: fill the valid_accs and train_accs lists with the model performance for the corresponding ccp_alpha values\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "### END SOLUTION    \n",
    "\n",
    "plt.plot(alpha_values, valid_accs, color='red')\n",
    "plt.plot(alpha_values, train_accs, color='blue')\n",
    "plt.xlabel(\"Post Pruning Alpha\")\n",
    "plt.ylabel(f'Average Accuracy of {k}-fold validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "hyperparameter_search_test",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(train_accs, [1.0, 1.0, 0.999865934065934, 0.9882065934065934, 0.9762131868131869, 0.9762131868131869, 0.9762131868131869, 0.9762131868131869, 0.9762285714285714, 0.9762417582417583, 0.9762417582417583, 0.9642417582417583, 0.9642417582417583, 0.9642417582417583, 0.964254945054945, 0.9643703296703297, 0.9643703296703297, 0.9643703296703297], decimal = 4)\n",
    "np.testing.assert_almost_equal(valid_accs, [0.9105659340659341, 0.9105659340659341, 0.9105659340659341, 0.9105615384615385, 0.9227615384615385, 0.9227593406593406, 0.9288593406593406, 0.9286537362637363, 0.9286237362637363, 0.9286237362637363, 0.9286237362637363, 0.9286237362637363, 0.9286237362637363, 0.9286237362637363, 0.9286237362637363, 0.9286237362637363, 0.9286237362637363, 0.9286237362637363], decimal = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c4d910003a085adb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Now answer the following questions:**\n",
    "1. How does training accuracy change as the alpha value changes? Why? \n",
    "2. How does the validation accuracy change as the alpha value chanegs? Why? \n",
    "3. Knowing this, what value would you choose for alpha for the final model? Why? Plot the final decision tree with your alpha selection. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "hp_discussion",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Discuss here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-05fc1c798c0da735",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The following code selects the alpha value for the best model. Then you job is to train a new model (using all of the training data), using your best hyperparameter value. Then evaluate it on the test dataset using accuracy score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the alpha for the model with the best accuracy on the *validation* set!\n",
    "best_alpha = alpha_values[np.argmax(valid_accs)]\n",
    "best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "train_best_ccp_alpha",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Train your decision tree classifier here with ccp_alpha equals to the best alpha find above.\n",
    "# Your decision tree should use gini index as split critirion.\n",
    "# Don't forget to set random_state=random_seed.\n",
    "# You may want to print the tree using plot_tree\n",
    "\n",
    "gini_tree = None\n",
    "\n",
    "#TODO: construct the gini_tree\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "_ = plot_tree(gini_tree, feature_names=seeds_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "train_best_ccp_alpha_test_2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Rememer there are hidden tests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "eval_best_ccp_alpha",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Now evaluate your model on the test dataset - what are the evaluation metrics?\n",
    "\n",
    "y_test_accuracy = None\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "print(y_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "eval_best_ccp_alpha_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert y_test_accuracy == 0.8571428571428571"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
